{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingestion(table):\n",
    "    load_dotenv()\n",
    "    connection = mysql.connector.connect(\n",
    "        host=os.getenv('HOST'),\n",
    "        user='root',\n",
    "        password=os.getenv('PASSWORD'),\n",
    "        database='capstone5'\n",
    "    )\n",
    "    query = f\"SELECT * FROM {table}\"  \n",
    "    df = pd.read_sql(query, connection)\n",
    "    connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of table names\n",
    "tables = [\n",
    "    'applications', 'articles', 'comments', 'donation_manual_comments',\n",
    "    'donation_manuals', 'fundraising_categories', 'fundraisings',\n",
    "    'likes_comments', 'organizations', 'testimoni_volunteers',\n",
    "    'user_bookmark_fundraisings', 'user_bookmark_volunteer_vacancies',\n",
    "    'volunteers', 'users', 'admins', 'like_donation_comments',\n",
    "    'user_bookmark_articles', 'user_bookmark_articles'\n",
    "]\n",
    "\n",
    "# Ingest data for all tables\n",
    "data_frame = [ingestion(table) for table in tables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Raw Data To Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_firebase():\n",
    "    if not firebase_admin._apps:\n",
    "        credentials_path = os.getenv('FIREBASE_CREDENTIALS_PATH')\n",
    "        cred = credentials.Certificate(credentials_path)\n",
    "        firebase_admin.initialize_app(cred)\n",
    "        print(\"Firebase has been initialized\")\n",
    "    else:\n",
    "        print(\"Firebase is already initialized\")\n",
    "    bucket_name = os.getenv('BUCKET_NAME')\n",
    "    return storage.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_in_bucket():\n",
    "    bucket = initialize_firebase()\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    folder_blob = bucket.blob(f\"{current_date}/\")\n",
    "    folder_blob.upload_from_string('')\n",
    "    print(f\"Folder '{current_date}' created successfully.\")\n",
    "    return current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataframes_to_firebase(data_frames):\n",
    "    current_date = create_folder_in_bucket()\n",
    "    bucket = initialize_firebase()\n",
    "    \n",
    "    for df, table_name in zip(data_frames, tables):\n",
    "        # Convert dataframe to CSV string\n",
    "        csv_str = df.to_csv(index=False)\n",
    "\n",
    "        # Create the blob reference with folder name\n",
    "        file_name_with_date = f\"{table_name}_{current_date}.csv\"\n",
    "        file_path_in_bucket = f\"{current_date}/{file_name_with_date}\"\n",
    "        file_ref = bucket.blob(file_path_in_bucket)\n",
    "        \n",
    "        # Upload CSV string to Firebase\n",
    "        file_ref.upload_from_string(csv_str, content_type='text/csv')\n",
    "        print(f\"Dataframe {table_name} uploaded successfully as {file_name_with_date}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all dataframes to Firebase\n",
    "upload_dataframes_to_firebase(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Value & Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek duplikat dan missing value\n",
    "\n",
    "def cleaning_data(df):\n",
    "    \n",
    "    # cek duplikat\n",
    "    duplicates = df[df.duplicated(subset=df.columns, keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        print(f\"Terdapat duplikat pada {df}\")\n",
    "        print(duplicates)\n",
    "        df = df.drop_duplicates()\n",
    "    else:\n",
    "        print(f\"Tidak ada data duplikat pada {df}\")\n",
    "        \n",
    "    # Ubah tipe data\n",
    "    columns_datetime = ['created_at', 'updated_at', 'deleted_at']\n",
    "    for col in columns_datetime:\n",
    "        if df[col].dtype != 'datetime64[ns]':\n",
    "            df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')\n",
    "        df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "\n",
    "    # cek missing value\n",
    "    missing_columns = [col for col in df.columns if col not in ['updated_at', 'deleted_at']]\n",
    "    # df[missing_columns] = df[missing_columns].replace('', None)\n",
    "    if df[missing_columns].isnull().any().any():\n",
    "        print(f\"Terdapat missing value dalam {df}\")\n",
    "        missing_sum = df[missing_columns].isnull().sum()\n",
    "        print(missing_sum)\n",
    "        \n",
    "        columns_numeric = ['total_likes', 'amount', 'goal_amount', 'current_progress', 'is_verified', 'registered_volunteer']\n",
    "        for col in missing_columns:\n",
    "            if df[col].dtype != 'object' and df[col].dtype != 'datetime64[ns]' and col not in columns_numeric:\n",
    "                df[col] = df[col].fillna(np.nan)\n",
    "            elif col in columns_numeric :\n",
    "                df[col] = df[col].fillna(0)\n",
    "            elif df[col].dtype == 'datetime64[ns]':\n",
    "                df[col] = df[col].fillna(pd.NaT)\n",
    "            else:\n",
    "                df[col] = df[col].fillna('Unknown')\n",
    "    else :\n",
    "        print(f\"Tidak ada missing value dalam {df}\")\n",
    "        missing_sum = df[missing_columns].isnull().sum()\n",
    "        print(missing_sum)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_frame :\n",
    "    cleaning_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications = data_frame[0]\n",
    "df_articles = data_frame[1]\n",
    "df_comments = data_frame[2]\n",
    "df_donation_manuals = data_frame[4]\n",
    "df_fundraising_categories = data_frame[5]\n",
    "df_fundraisings = data_frame[6]\n",
    "df_like_comments = data_frame[7]\n",
    "df_organizations = data_frame[8]\n",
    "df_testimoni_volunteers = data_frame[9]\n",
    "df_user_bookmark_fundraisings = data_frame[10]\n",
    "df_user_bookmark_volunteer_vacancies = data_frame[11]\n",
    "df_volunteers = data_frame[12]\n",
    "df_users = data_frame[13]\n",
    "df_user_bookmark_articles = data_frame[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabel Fakta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. FactDonationTransaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat Struktur kolom fact_donation_transaction\n",
    "columns = ['id', 'donation_id', 'fundraising_id', 'user_id', 'amount', 'goal_amount', 'fundraising_category_id', 'organization_id', 'created_at']\n",
    "fact_donation = pd.DataFrame(columns=columns)\n",
    "\n",
    "# mengambil data yang sukses di df_donation \n",
    "df_donation_success = df_donation_manuals.loc[df_donation_manuals['status'] == 'sukses']\n",
    "df_donation_success = df_donation_success.reset_index(drop=True)\n",
    "\n",
    "# mengisi data pada dari kolom df_donation\n",
    "fact_donation['id'] = range(1, len(df_donation_success) + 1)\n",
    "fact_donation['donation_id'] = df_donation_success['id']\n",
    "fact_donation['fundraising_id'] = df_donation_success['fundraising_id']\n",
    "fact_donation['user_id'] = df_donation_success['user_id']\n",
    "fact_donation['amount'] = df_donation_success['amount']\n",
    "fact_donation['created_at'] = df_donation_success['created_at']\n",
    "\n",
    "# merge df_fundraising\n",
    "df_merge_fact_fundraising = pd.merge(fact_donation, df_fundraisings, left_on='fundraising_id', right_on='id', how='left')\n",
    "fact_donation['goal_amount'] = df_merge_fact_fundraising['goal_amount_y']\n",
    "fact_donation['fundraising_category_id'] = df_merge_fact_fundraising['fundraising_category_id_y']\n",
    "fact_donation['organization_id'] = df_merge_fact_fundraising['organization_id_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. FactVolunteerApplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat Struktur kolom df_fact_volunteer_applications\n",
    "columns = ['id', 'application_id', 'vacancy_id', 'user_id', 'organization_id', 'created_at']\n",
    "fact_applications = pd.DataFrame(columns=columns)\n",
    "\n",
    "# mengisi data pada dari kolom df_application\n",
    "fact_applications['id'] = range(1, len(df_applications) + 1)\n",
    "fact_applications['application_id'] = df_applications['id']\n",
    "fact_applications['vacancy_id'] = df_applications['vacancy_id']\n",
    "fact_applications['user_id'] = df_applications['user_id']\n",
    "fact_applications['created_at'] = df_applications['created_at']\n",
    "\n",
    "# merge df_fundraising\n",
    "df_merge_fact_volunteer = pd.merge(fact_applications, df_volunteers, left_on='vacancy_id', right_on='id', how='left')\n",
    "fact_applications['organization_id'] = df_merge_fact_volunteer['organization_id_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. FactVolunteerTestimoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat Struktur kolom df_fact_volunteer_testimoni\n",
    "columns = ['id', 'user_id', 'vacancy_id', 'testimoni_volunteer_id', 'rating', 'created_at']\n",
    "fact_volunteer_testimoni = pd.DataFrame(columns=columns)\n",
    "\n",
    "# mengisi data pada dari kolom df_application\n",
    "fact_volunteer_testimoni['id'] = range(1, len(df_testimoni_volunteers) + 1)\n",
    "fact_volunteer_testimoni['user_id'] = df_testimoni_volunteers['user_id']\n",
    "fact_volunteer_testimoni['vacancy_id'] = df_testimoni_volunteers['vacancy_id']\n",
    "fact_volunteer_testimoni['testimoni_volunteer_id'] = df_testimoni_volunteers['id']\n",
    "fact_volunteer_testimoni['rating'] = df_testimoni_volunteers['rating']\n",
    "fact_volunteer_testimoni['created_at'] = df_testimoni_volunteers['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. FactArticlePopular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat Struktur kolom df_fact_articel_popular\n",
    "columns = ['id', 'article_id', 'bookmark_id', 'user_id','comment_id', 'like_comment_id', 'created_at']\n",
    "fact_article_popular = pd.DataFrame(columns=columns)\n",
    "\n",
    "# mengisi data pada dari kolom df_comment\n",
    "fact_article_popular['id'] = range(1, len(df_user_bookmark_articles) + 1)\n",
    "fact_article_popular['article_id'] = df_user_bookmark_articles['article_id']\n",
    "fact_article_popular['bookmark_id'] = df_user_bookmark_articles['id']\n",
    "fact_article_popular['user_id'] = df_user_bookmark_articles['user_id']\n",
    "fact_article_popular['comment_id'] = df_comments['id']\n",
    "fact_article_popular['like_comment_id'] = df_like_comments['id']\n",
    "fact_article_popular['created_at'] = df_user_bookmark_articles['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. FactBookmarkFundraising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_bookmark_fundraising = df_user_bookmark_fundraisings.drop(['deleted_at', 'updated_at'], axis=1)\n",
    "fact_bookmark_fundraising = fact_bookmark_fundraising.rename(columns={'id':'bookmark_id'})\n",
    "fact_bookmark_fundraising['id'] = range(1, len(fact_bookmark_fundraising) + 1)\n",
    "fact_bookmark_fundraising.insert(0, 'id', fact_bookmark_fundraising.pop('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. FactBookmarkVolunteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_bookmark_volunteer_vacancies = df_user_bookmark_volunteer_vacancies.drop(['deleted_at', 'updated_at','volunteer_vacancy_id'], axis=1)\n",
    "fact_bookmark_volunteer_vacancies = fact_bookmark_volunteer_vacancies.rename(columns={'id':'bookmark_id'})\n",
    "fact_bookmark_volunteer_vacancies['id'] = range(1, len(fact_bookmark_volunteer_vacancies) + 1)\n",
    "fact_bookmark_volunteer_vacancies.insert(0, 'id', fact_bookmark_volunteer_vacancies.pop('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabel Dimensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_fundraisings = df_fundraisings.drop(['fundraising_category_id','organization_id','updated_at'], axis=1)\n",
    "dim_fundraising_categories = df_fundraising_categories[['id','name','created_at']]\n",
    "dim_donation_manual = df_donation_manuals.drop(['fundraising_id', 'user_id','updated_at'], axis=1)\n",
    "dim_organization = df_organizations.drop(['updated_at'], axis= 1)\n",
    "dim_user = df_users.drop(['updated_at'], axis=1)\n",
    "dim_volunteer_applictaion = df_applications.drop(['user_id','vacancy_id','updated_at'], axis=1)\n",
    "dim_volunteer_vacancies = df_volunteers.drop(['organization_id','updated_at'], axis=1)\n",
    "dim_testimoni_volunteer = df_testimoni_volunteers.drop(['user_id','vacancy_id','updated_at'], axis=1)\n",
    "dim_article = df_articles.drop(['updated_at'], axis = 1)\n",
    "dim_bookmark_fundraising = df_user_bookmark_fundraisings.drop(['fundraising_id','user_id','updated_at'], axis=1)\n",
    "dim_bookmark_volunter_vacancies = df_user_bookmark_volunteer_vacancies.drop(['volunteer_vacancies_id','user_id','updated_at'], axis=1)\n",
    "dim_bookmark_article = df_user_bookmark_articles.drop(['deleted_at','updated_at'], axis=1)\n",
    "\n",
    "dim_comments = df_comments.drop(['user_id','article_id','updated_at'], axis=1)\n",
    "dim_like_comments = df_like_comments.drop(['user_id','comment_id', 'updated_at'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact = [\n",
    "    ('fact_applications', fact_applications),\n",
    "    ('fact_article_popular', fact_article_popular),\n",
    "    ('fact_bookmark_fundraising', fact_bookmark_fundraising),\n",
    "    ('fact_bookmark_volunteer_vacancies', fact_bookmark_volunteer_vacancies),\n",
    "    ('fact_donation', fact_donation),\n",
    "    ('fact_volunteer_testimoni', fact_volunteer_testimoni)\n",
    "]\n",
    "\n",
    "df_dim = [\n",
    "    ('dim_article', dim_article),\n",
    "    ('dim_bookmark_fundraising', dim_bookmark_fundraising),\n",
    "    ('dim_bookmark_volunter_vacancies', dim_bookmark_volunter_vacancies),\n",
    "    ('dim_bookmark_article', dim_bookmark_article),\n",
    "    ('dim_donation_manual', dim_donation_manual),\n",
    "    ('dim_fundraising_categories', dim_fundraising_categories),\n",
    "    ('dim_fundraisings', dim_fundraisings),\n",
    "    ('dim_organization', dim_organization),\n",
    "    ('dim_testimoni_volunteer', dim_testimoni_volunteer),\n",
    "    ('dim_user', dim_user),\n",
    "    ('dim_volunteer_application', dim_volunteer_applictaion),\n",
    "    ('dim_volunteer_vacancies', dim_volunteer_vacancies),\n",
    "    ('dim_comments', dim_comments),\n",
    "    ('dim_like_comments', dim_like_comments)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load To Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if credentials_path:\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "else:\n",
    "    raise Exception(\"GOOGLE_APPLICATION_CREDENTIALS is not set in the .env file\")\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "dataset_id_fact = os.getenv(\"dataset_id_fact\")\n",
    "dataset_id_dim = os.getenv(\"dataset_id_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_to_bigquery(dataset_id, table_name, df):\n",
    "    # Create a BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Convert DataFrame to CSV\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "\n",
    "    table_id = f\"{dataset_id}.{table_name}\"\n",
    "    \n",
    "    partition_by = bigquery.TimePartitioning(field=\"created_at\")\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,\n",
    "        autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "        time_partitioning=partition_by\n",
    "    )\n",
    "\n",
    "    # Load CSV data from StringIO buffer\n",
    "    job = client.load_table_from_file(csv_buffer, table_id, job_config=job_config)\n",
    "    \n",
    "    # Wait for the load job to complete\n",
    "    job.result()\n",
    "\n",
    "    # Get table information\n",
    "    table = client.get_table(table_id)\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), table_id\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fact tables\n",
    "for table_name, df in df_fact:\n",
    "    load_df_to_bigquery(dataset_id_fact, table_name, df)\n",
    "\n",
    "# Load dimension tables\n",
    "for table_name, df in df_dim:\n",
    "    load_df_to_bigquery(dataset_id_dim, table_name, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
